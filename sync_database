#!/bin/bash

# sync_database - Remote PostgreSQL database dump and sync script
# Usage: bash sync_database --database dbname --username user --password pass --exclude table1,table2

set -e

# Get the directory where this script is located
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Source health check functions
if [ -f "${SCRIPT_DIR}/health_checks" ]; then
    source "${SCRIPT_DIR}/health_checks"
fi

# Source retention policy functions
if [ -f "${SCRIPT_DIR}/retention_policies" ]; then
    source "${SCRIPT_DIR}/retention_policies"
fi

# Source alerting functions
if [ -f "${SCRIPT_DIR}/alerting" ]; then
    source "${SCRIPT_DIR}/alerting"
fi

# Source streaming functions
if [ -f "${SCRIPT_DIR}/streaming" ]; then
    source "${SCRIPT_DIR}/streaming"
fi

# Source data masking functions
if [ -f "${SCRIPT_DIR}/data_masking" ]; then
    source "${SCRIPT_DIR}/data_masking"
fi

# Source multi-source functions
if [ -f "${SCRIPT_DIR}/multi_source" ]; then
    source "${SCRIPT_DIR}/multi_source"
fi

# Source PITR functions
if [ -f "${SCRIPT_DIR}/pitr" ]; then
    source "${SCRIPT_DIR}/pitr"
fi

# Default values
DATABASE="your_database_name"
EXCLUDE_TABLES=""
EXCLUDE_SCHEMAS=""
EXCLUDE_TABLE_DATA=""
AUTO_RESTORE=false
KEEP_DUMPS=-1  # -1 means keep all dumps, 0 means keep none, N means keep last N dumps
LOCAL_CLONE=false  # Clone database on localhost without SSH

# Health check settings
HEALTH_CHECK_ENABLED=true
HEALTH_CHECK_PRE_SYNC=true
HEALTH_CHECK_POST_SYNC=false
HEALTH_CHECK_FAIL_ON_ERROR=false

# Compression settings
COMPRESSION_ENABLED=true
COMPRESSION_TYPE="gzip"  # External compression: gzip, xz, bzip2, none
COMPRESSION_LEVEL=6      # External compression level: 1-9 (1=fast, 9=best compression)
PG_DUMP_COMPRESSION=6    # PostgreSQL internal compression: 0-9 (pg_dump -Z flag, for custom format)

# Source database configuration (where to dump from)
SOURCE_DB_HOST="localhost"
SOURCE_DB_PORT="5432"
SOURCE_DB_USER="postgres"
SOURCE_DB_PASSWORD=""

# Destination database configuration (where to restore to)
DEST_DB_NAME=""
DEST_DB_HOST="localhost"
DEST_DB_PORT="5432"
DEST_DB_USER="postgres"
DEST_DB_PASSWORD=""

# Remote server configuration (SSH RSA key configured)
REMOTE_USER="your_ssh_user"
REMOTE_HOST=""
REMOTE_PORT="22"
REMOTE_DUMP_DIR="/tmp"

# Local configuration
LOCAL_DUMP_DIR="${SCRIPT_DIR}/data/dumps"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Function to load global options from JSON config if available
load_global_config() {
    local config_file="${SCRIPT_DIR}/sync_database.json"

    # Check if config file exists and jq is available
    if [ -f "$config_file" ] && command -v jq &> /dev/null; then
        echo -e "${GREEN}Loading global configuration from sync_database.json...${NC}"

        # Load Telegram settings (for alerting module)
        local telegram_enabled=$(jq -r '.global_options.telegram.enabled // false' "$config_file" 2>/dev/null)
        if [ "$telegram_enabled" = "true" ]; then
            ALERT_TELEGRAM_ENABLED=true
            ALERT_TELEGRAM_BOT_TOKEN=$(jq -r '.global_options.telegram.bot_token // ""' "$config_file" 2>/dev/null)
            ALERT_TELEGRAM_CHAT_ID=$(jq -r '.global_options.telegram.chat_id // ""' "$config_file" 2>/dev/null)
            ALERTING_ENABLED=true
        fi

        # Load alerting webhook settings
        local webhook_url=$(jq -r '.global_options.alerting.webhook.url // ""' "$config_file" 2>/dev/null)
        if [ -n "$webhook_url" ]; then
            ALERT_WEBHOOK_ENABLED=true
            ALERT_WEBHOOK_URL="$webhook_url"
            ALERTING_ENABLED=true

            # Load webhook headers if provided
            local webhook_headers=$(jq -c '.global_options.alerting.webhook.headers // {}' "$config_file" 2>/dev/null)
            if [ -n "$webhook_headers" ] && [ "$webhook_headers" != "{}" ] && [ "$webhook_headers" != "null" ]; then
                ALERT_WEBHOOK_HEADERS="$webhook_headers"
            fi
        fi

        # Load alerting email settings
        local email_enabled=$(jq -r '.global_options.alerting.email.enabled // false' "$config_file" 2>/dev/null)
        if [ "$email_enabled" = "true" ]; then
            ALERT_EMAIL_ENABLED=true
            ALERT_EMAIL_SMTP_HOST=$(jq -r '.global_options.alerting.email.smtp_host // "smtp.gmail.com"' "$config_file" 2>/dev/null)
            ALERT_EMAIL_SMTP_PORT=$(jq -r '.global_options.alerting.email.smtp_port // 587' "$config_file" 2>/dev/null)
            ALERT_EMAIL_SMTP_USER=$(jq -r '.global_options.alerting.email.smtp_user // ""' "$config_file" 2>/dev/null)
            ALERT_EMAIL_SMTP_PASSWORD=$(jq -r '.global_options.alerting.email.smtp_password // ""' "$config_file" 2>/dev/null)
            ALERT_EMAIL_FROM=$(jq -r '.global_options.alerting.email.from // ""' "$config_file" 2>/dev/null)
            ALERT_EMAIL_TO=$(jq -r '.global_options.alerting.email.to // ""' "$config_file" 2>/dev/null)
            ALERTING_ENABLED=true
        fi

        # Load alerting severity
        ALERT_MIN_SEVERITY=$(jq -r '.global_options.alerting.min_severity // "warning"' "$config_file" 2>/dev/null)

        # Load health check settings
        local health_enabled=$(jq -r '.global_options.health_checks.enabled // true' "$config_file" 2>/dev/null)
        if [ "$health_enabled" = "false" ]; then
            HEALTH_CHECK_ENABLED=false
        fi
        local health_pre=$(jq -r '.global_options.health_checks.pre_sync // true' "$config_file" 2>/dev/null)
        if [ "$health_pre" = "false" ]; then
            HEALTH_CHECK_PRE_SYNC=false
        fi
        local health_post=$(jq -r '.global_options.health_checks.post_sync // false' "$config_file" 2>/dev/null)
        if [ "$health_post" = "true" ]; then
            HEALTH_CHECK_POST_SYNC=true
        fi

        # Load health check thresholds
        local conn_timeout=$(jq -r '.global_options.health_checks.connection_timeout // ""' "$config_file" 2>/dev/null)
        if [ -n "$conn_timeout" ] && [ "$conn_timeout" != "null" ]; then
            export HEALTH_CHECK_CONNECTION_TIMEOUT="$conn_timeout"
        fi
        local disk_threshold=$(jq -r '.global_options.health_checks.disk_space_threshold // ""' "$config_file" 2>/dev/null)
        if [ -n "$disk_threshold" ] && [ "$disk_threshold" != "null" ]; then
            export HEALTH_CHECK_DISK_MIN_GB="$disk_threshold"
        fi
        local repl_threshold=$(jq -r '.global_options.health_checks.replication_lag_threshold // ""' "$config_file" 2>/dev/null)
        if [ -n "$repl_threshold" ] && [ "$repl_threshold" != "null" ]; then
            export HEALTH_CHECK_REPLICATION_LAG_MAX_SEC="$repl_threshold"
        fi
        local query_threshold=$(jq -r '.global_options.health_checks.long_query_threshold // ""' "$config_file" 2>/dev/null)
        if [ -n "$query_threshold" ] && [ "$query_threshold" != "null" ]; then
            export HEALTH_CHECK_LONG_QUERY_MAX_SEC="$query_threshold"
        fi
        local lock_threshold=$(jq -r '.global_options.health_checks.lock_wait_threshold // ""' "$config_file" 2>/dev/null)
        if [ -n "$lock_threshold" ] && [ "$lock_threshold" != "null" ]; then
            export HEALTH_CHECK_LOCK_WAIT_THRESHOLD="$lock_threshold"
        fi
        local bloat_threshold=$(jq -r '.global_options.health_checks.bloat_threshold // ""' "$config_file" 2>/dev/null)
        if [ -n "$bloat_threshold" ] && [ "$bloat_threshold" != "null" ]; then
            export HEALTH_CHECK_TABLE_BLOAT_MAX_PERCENT="$bloat_threshold"
        fi

        # Load retention policy settings
        local retention_enabled=$(jq -r '.global_options.retention_policy.enabled // false' "$config_file" 2>/dev/null)
        if [ "$retention_enabled" = "true" ]; then
            RETENTION_ENABLED=true
            RETENTION_STRATEGY=$(jq -r '.global_options.retention_policy.strategy // "gfs"' "$config_file" 2>/dev/null)
            RETENTION_DAILY=$(jq -r '.global_options.retention_policy.daily // 7' "$config_file" 2>/dev/null)
            RETENTION_WEEKLY=$(jq -r '.global_options.retention_policy.weekly // 4' "$config_file" 2>/dev/null)
            RETENTION_MONTHLY=$(jq -r '.global_options.retention_policy.monthly // 12' "$config_file" 2>/dev/null)
            RETENTION_YEARLY=$(jq -r '.global_options.retention_policy.yearly // 3' "$config_file" 2>/dev/null)
        fi

        # Load log_file setting
        local log_file=$(jq -r '.global_options.log_file // ""' "$config_file" 2>/dev/null)
        if [ -n "$log_file" ] && [ "$log_file" != "null" ]; then
            export LOG_FILE="$log_file"
            # Create log directory if it doesn't exist
            mkdir -p "$(dirname "$log_file")" 2>/dev/null
        fi

        # Load keep_dumps if not using retention policy
        if [ "$RETENTION_ENABLED" != "true" ]; then
            local keep_dumps=$(jq -r '.global_options.keep_dumps // -1' "$config_file" 2>/dev/null)
            # Accept any valid number: -1 (keep all), 0 (keep none), or N (keep last N)
            if [ "$keep_dumps" != "null" ] && [ "$keep_dumps" -ge -1 ]; then
                KEEP_DUMPS="$keep_dumps"
            fi
        fi

        echo -e "${GREEN}✓ Global configuration loaded${NC}"
        echo ""
    fi
}

# Load global configuration if available
load_global_config

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --database)
            DATABASE="$2"
            shift 2
            ;;
        --exclude)
            EXCLUDE_TABLES="$2"
            shift 2
            ;;
        --exclude-schema)
            EXCLUDE_SCHEMAS="$2"
            shift 2
            ;;
        --exclude-table-data)
            EXCLUDE_TABLE_DATA="$2"
            shift 2
            ;;
        --remote-user)
            REMOTE_USER="$2"
            shift 2
            ;;
        --remote-ip)
            REMOTE_HOST="$2"
            shift 2
            ;;
        --remote-port)
            REMOTE_PORT="$2"
            shift 2
            ;;
        --source-host)
            SOURCE_DB_HOST="$2"
            shift 2
            ;;
        --source-port)
            SOURCE_DB_PORT="$2"
            shift 2
            ;;
        --source-user)
            SOURCE_DB_USER="$2"
            shift 2
            ;;
        --source-password)
            SOURCE_DB_PASSWORD="$2"
            shift 2
            ;;
        --restore)
            AUTO_RESTORE=true
            shift 1
            ;;
        --dest-database)
            DEST_DB_NAME="$2"
            shift 2
            ;;
        --dest-host)
            DEST_DB_HOST="$2"
            shift 2
            ;;
        --dest-port)
            DEST_DB_PORT="$2"
            shift 2
            ;;
        --dest-user)
            DEST_DB_USER="$2"
            shift 2
            ;;
        --dest-password)
            DEST_DB_PASSWORD="$2"
            shift 2
            ;;
        --compression)
            COMPRESSION_TYPE="$2"
            if [ "$COMPRESSION_TYPE" = "none" ]; then
                COMPRESSION_ENABLED=false
            fi
            shift 2
            ;;
        --compression-level)
            COMPRESSION_LEVEL="$2"
            shift 2
            ;;
        --pg-compression)
            PG_DUMP_COMPRESSION="$2"
            shift 2
            ;;
        --keep-dumps)
            KEEP_DUMPS="$2"
            shift 2
            ;;
        --local-clone)
            LOCAL_CLONE=true
            AUTO_RESTORE=true
            shift 1
            ;;
        --health-check)
            HEALTH_CHECK_ENABLED=true
            shift 1
            ;;
        --no-health-check)
            HEALTH_CHECK_ENABLED=false
            shift 1
            ;;
        --health-check-pre)
            HEALTH_CHECK_PRE_SYNC=true
            shift 1
            ;;
        --health-check-post)
            HEALTH_CHECK_POST_SYNC=true
            shift 1
            ;;
        --health-check-fail-on-error)
            HEALTH_CHECK_FAIL_ON_ERROR=true
            shift 1
            ;;
        --retention-policy)
            RETENTION_ENABLED=true
            RETENTION_STRATEGY="$2"
            shift 2
            ;;
        --retention-daily)
            RETENTION_DAILY="$2"
            shift 2
            ;;
        --retention-weekly)
            RETENTION_WEEKLY="$2"
            shift 2
            ;;
        --retention-monthly)
            RETENTION_MONTHLY="$2"
            shift 2
            ;;
        --retention-yearly)
            RETENTION_YEARLY="$2"
            shift 2
            ;;
        --alert-webhook)
            ALERTING_ENABLED=true
            ALERT_WEBHOOK_ENABLED=true
            ALERT_WEBHOOK_URL="$2"
            shift 2
            ;;
        --alert-email)
            ALERTING_ENABLED=true
            ALERT_EMAIL_ENABLED=true
            ALERT_EMAIL_TO="$2"
            shift 2
            ;;
        --alert-severity)
            ALERT_MIN_SEVERITY="$2"
            shift 2
            ;;
        --streaming)
            STREAMING_ENABLED=true
            shift 1
            ;;
        --no-progress)
            STREAMING_SHOW_PROGRESS=false
            shift 1
            ;;
        --data-masking)
            DATA_MASKING_ENABLED=true
            shift 1
            ;;
        --masking-rules)
            DATA_MASKING_RULES_FILE="$2"
            shift 2
            ;;
        --help)
            echo "Usage: bash sync_database [OPTIONS]"
            echo ""
            echo "Options:"
            echo "  --database NAME            Source database name (default: your_database_name)"
            echo "  --exclude TABLES           Comma-separated list of tables to exclude (structure + data)"
            echo "  --exclude-schema SCHEMAS   Comma-separated list of schemas to exclude"
            echo "  --exclude-table-data TABLES  Comma-separated list of tables to exclude data only (keeps structure)"
            echo ""
            echo "Mode Options:"
            echo "  --local-clone              Clone database on localhost (no SSH needed)"
            echo ""
            echo "Remote Server Options (SSH connection, not needed for --local-clone):"
            echo "  --remote-user USER         SSH username (default: your_ssh_user)"
            echo "  --remote-ip IP             SSH server IP (required for remote sync)"
            echo "  --remote-port PORT         SSH port (default: 22)"
            echo ""
            echo "Source Database Options (where to dump from):"
            echo "  --source-host HOST         Source DB host on remote server (default: localhost)"
            echo "  --source-port PORT         Source DB port (default: 5432)"
            echo "  --source-user USER         Source DB username (default: postgres)"
            echo "  --source-password PASS     Source DB password (required)"
            echo ""
            echo "Destination Database Options (where to restore to):"
            echo "  --restore                  Automatically restore after sync"
            echo "  --dest-database NAME       Destination DB name (default: same as source)"
            echo "  --dest-host HOST           Destination DB host (default: localhost)"
            echo "  --dest-port PORT           Destination DB port (default: 5432)"
            echo "  --dest-user USER           Destination DB username (default: postgres)"
            echo "  --dest-password PASS       Destination DB password (required for restore)"
            echo ""
            echo "Compression Options:"
            echo "  --compression TYPE         External compression type: gzip, xz, bzip2, none (default: gzip)"
            echo "  --compression-level LEVEL  External compression level 1-9 (1=fast, 9=best) (default: 6)"
            echo "  --pg-compression LEVEL     PostgreSQL internal dump compression 0-9 (pg_dump -Z flag) (default: 6)"
            echo ""
            echo "Dump Management:"
            echo "  --keep-dumps N             Keep dump policy: -1=keep all, 0=keep none, N=keep last N (default: -1)"
            echo ""
            echo "Health Check Options:"
            echo "  --health-check             Enable health checks (default: enabled)"
            echo "  --no-health-check          Disable all health checks"
            echo "  --health-check-pre         Run health checks before sync (default: enabled)"
            echo "  --health-check-post        Run health checks after sync"
            echo "  --health-check-fail-on-error  Fail if health check errors detected"
            echo ""
            echo "Retention Policy Options:"
            echo "  --retention-policy STRATEGY   Retention strategy: gfs (grandfather-father-son) or simple"
            echo "  --retention-daily N          Keep last N daily backups (default: 7)"
            echo "  --retention-weekly N         Keep last N weekly backups (default: 4)"
            echo "  --retention-monthly N        Keep last N monthly backups (default: 12)"
            echo "  --retention-yearly N         Keep last N yearly backups (default: 3)"
            echo ""
            echo "Alerting Options:"
            echo "  --alert-webhook URL          Send alerts to webhook URL"
            echo "  --alert-email EMAIL          Send alerts to email address"
            echo "  --alert-severity LEVEL       Minimum severity: info, warning, error, critical (default: warning)"
            echo "  Note: Telegram alerts use existing bot token and chat ID"
            echo ""
            echo "Streaming Options:"
            echo "  --streaming                  Enable streaming mode (no intermediate dump files)"
            echo "  --no-progress                Disable progress display in streaming mode"
            echo ""
            echo "Data Masking Options:"
            echo "  --data-masking               Enable data masking (default: false)"
            echo "  --masking-rules FILE         JSON file with masking rules"
            echo ""
            echo "  --help                     Show this help message"
            echo ""
            echo "Examples:"
            echo "  # Dump only from remote server"
            echo "  bash sync_database --database mydb --source-password secret --remote-ip 192.168.1.100"
            echo ""
            echo "  # Dump from remote DB on different host and restore locally"
            echo "  bash sync_database --database mydb \\"
            echo "    --source-password secret --source-host 10.0.0.5 \\"
            echo "    --remote-ip 192.168.1.100 \\"
            echo "    --restore --dest-password localpass"
            echo ""
            echo "  # Restore to different database name"
            echo "  bash sync_database --database proddb \\"
            echo "    --source-password secret --remote-ip 192.168.1.100 \\"
            echo "    --restore --dest-database devdb --dest-password localpass"
            echo ""
            echo "  # With exclude tables"
            echo "  bash sync_database --database mydb \\"
            echo "    --source-password secret --remote-ip 192.168.1.100 \\"
            echo "    --exclude logs,sessions --restore --dest-password localpass"
            echo ""
            echo "  # Clone database on localhost (no SSH)"
            echo "  bash sync_database --local-clone \\"
            echo "    --database mydb --source-password secret \\"
            echo "    --dest-database mydb_clone --dest-password secret"
            echo ""
            echo "  # Clone with different users"
            echo "  bash sync_database --local-clone \\"
            echo "    --database proddb --source-user admin --source-password secret \\"
            echo "    --dest-database testdb --dest-user testuser --dest-password testpass"
            exit 0
            ;;
        *)
            echo -e "${RED}Error: Unknown option: $1${NC}"
            echo "Use --help for usage information"
            exit 1
            ;;
    esac
done

# Validate required parameters
if [ -z "$SOURCE_DB_PASSWORD" ]; then
    echo -e "${RED}Error: --source-password is required${NC}"
    exit 1
fi

if [ "$LOCAL_CLONE" = false ] && [ -z "$REMOTE_HOST" ]; then
    echo -e "${RED}Error: --remote-ip is required (or use --local-clone for localhost cloning)${NC}"
    exit 1
fi

if [ "$AUTO_RESTORE" = true ] && [ -z "$DEST_DB_PASSWORD" ]; then
    echo -e "${RED}Error: --dest-password is required when using --restore${NC}"
    exit 1
fi

# Set destination database name to source if not specified
if [ -z "$DEST_DB_NAME" ]; then
    DEST_DB_NAME="$DATABASE"
fi

# Validate local clone constraints
if [ "$LOCAL_CLONE" = true ]; then
    if [ "$DATABASE" = "$DEST_DB_NAME" ]; then
        echo -e "${RED}Error: In local clone mode, source and destination database names cannot be the same${NC}"
        echo "Source: $DATABASE"
        echo "Destination: $DEST_DB_NAME"
        echo "Use --dest-database to specify a different name for the cloned database"
        exit 1
    fi

    # If ports are the same, use same credentials (same cluster)
    if [ "$SOURCE_DB_PORT" = "$DEST_DB_PORT" ] && [ "$SOURCE_DB_HOST" = "$DEST_DB_HOST" ]; then
        # Same cluster - use source credentials for destination if not specified
        if [ -z "$DEST_DB_USER" ] || [ "$DEST_DB_USER" = "postgres" ]; then
            DEST_DB_USER="$SOURCE_DB_USER"
        fi
        if [ -z "$DEST_DB_PASSWORD" ]; then
            DEST_DB_PASSWORD="$SOURCE_DB_PASSWORD"
        fi
    fi
fi

# Create local dump directory if it doesn't exist
mkdir -p "$LOCAL_DUMP_DIR"

# Generate dump filename
DUMP_FILENAME="${DATABASE}_${TIMESTAMP}.dump"
REMOTE_DUMP_PATH="${REMOTE_DUMP_DIR}/${DUMP_FILENAME}"
LOCAL_DUMP_PATH="${LOCAL_DUMP_DIR}/${DUMP_FILENAME}"

# Compression file extensions
case "$COMPRESSION_TYPE" in
    gzip)
        COMPRESSION_EXT=".gz"
        COMPRESS_CMD="gzip -${COMPRESSION_LEVEL}"
        DECOMPRESS_CMD="gunzip"
        ;;
    xz)
        COMPRESSION_EXT=".xz"
        COMPRESS_CMD="xz -${COMPRESSION_LEVEL}"
        DECOMPRESS_CMD="unxz"
        ;;
    bzip2)
        COMPRESSION_EXT=".bz2"
        COMPRESS_CMD="bzip2 -${COMPRESSION_LEVEL}"
        DECOMPRESS_CMD="bunzip2"
        ;;
    none)
        COMPRESSION_EXT=""
        COMPRESS_CMD=""
        DECOMPRESS_CMD=""
        COMPRESSION_ENABLED=false
        ;;
    *)
        echo -e "${RED}Error: Invalid compression type: $COMPRESSION_TYPE${NC}"
        echo "Valid types: gzip, xz, bzip2, none"
        exit 1
        ;;
esac

if [ "$LOCAL_CLONE" = true ]; then
    echo -e "${GREEN}=== PostgreSQL Local Clone Started ===${NC}"
    echo "Mode: Local Clone (No SSH)"
else
    echo -e "${GREEN}=== PostgreSQL Database Sync Started ===${NC}"
fi

echo "Source Database: $DATABASE"
echo "Source DB: ${SOURCE_DB_HOST}:${SOURCE_DB_PORT} (user: ${SOURCE_DB_USER})"

# Run pre-sync health checks
if [ "$HEALTH_CHECK_ENABLED" = true ] && [ "$HEALTH_CHECK_PRE_SYNC" = true ]; then
    if command -v run_health_checks &> /dev/null; then
        run_health_checks "$SOURCE_DB_HOST" "$SOURCE_DB_PORT" "$SOURCE_DB_USER" "$SOURCE_DB_PASSWORD" "$DATABASE" "Source"

        if [ $? -ne 0 ] && [ "$HEALTH_CHECK_FAIL_ON_ERROR" = true ]; then
            echo -e "${RED}✗ Health check failed with errors. Aborting operation.${NC}"
            exit 1
        fi
    fi
fi

if [ "$LOCAL_CLONE" = false ]; then
    echo "Remote SSH: ${REMOTE_USER}@${REMOTE_HOST}:${REMOTE_PORT}"
fi

if [ "$AUTO_RESTORE" = true ]; then
    echo "Destination Database: $DEST_DB_NAME"
    echo "Destination DB: ${DEST_DB_HOST}:${DEST_DB_PORT} (user: ${DEST_DB_USER})"
fi
if [ -n "$EXCLUDE_TABLES" ]; then
    echo "Excluding tables (structure + data): $EXCLUDE_TABLES"
fi
if [ -n "$EXCLUDE_SCHEMAS" ]; then
    echo "Excluding schemas: $EXCLUDE_SCHEMAS"
fi
if [ -n "$EXCLUDE_TABLE_DATA" ]; then
    echo "Excluding table data only (keeping structure): $EXCLUDE_TABLE_DATA"
fi
if [ "$COMPRESSION_ENABLED" = true ] && [ "$LOCAL_CLONE" = false ]; then
    echo "Compression: ${COMPRESSION_TYPE} (level: ${COMPRESSION_LEVEL}, pg_dump: ${PG_DUMP_COMPRESSION})"
elif [ "$LOCAL_CLONE" = true ]; then
    echo "Compression: disabled (local clone mode)"
    COMPRESSION_ENABLED=false
else
    echo "Compression: disabled"
fi
echo ""

# Build pg_dump command with exclude options
# -Fc: Custom format
# -Z: Compression level for custom format
# -v: Verbose
if [ "$LOCAL_CLONE" = true ]; then
    DUMP_PATH="$LOCAL_DUMP_PATH"
else
    DUMP_PATH="$REMOTE_DUMP_PATH"
fi

# Build pg_dump command
# For remote sync: include PGPASSWORD in command (SSH will handle it securely)
# For local clone: use export/unset pattern
if [ "$LOCAL_CLONE" = true ]; then
    PG_DUMP_CMD="pg_dump -U $SOURCE_DB_USER -h $SOURCE_DB_HOST -p $SOURCE_DB_PORT -Fc -Z${PG_DUMP_COMPRESSION} -v -f $DUMP_PATH $DATABASE"
else
    PG_DUMP_CMD="PGPASSWORD='$SOURCE_DB_PASSWORD' pg_dump -U $SOURCE_DB_USER -h $SOURCE_DB_HOST -p $SOURCE_DB_PORT -Fc -Z${PG_DUMP_COMPRESSION} -v -f $DUMP_PATH $DATABASE"
fi

# Add exclude-table options
if [ -n "$EXCLUDE_TABLES" ]; then
    IFS=',' read -ra TABLES <<< "$EXCLUDE_TABLES"
    for table in "${TABLES[@]}"; do
        # Trim whitespace
        table=$(echo "$table" | xargs)
        PG_DUMP_CMD="$PG_DUMP_CMD --exclude-table='$table'"
    done
fi

# Add exclude-schema options
if [ -n "$EXCLUDE_SCHEMAS" ]; then
    IFS=',' read -ra SCHEMAS <<< "$EXCLUDE_SCHEMAS"
    for schema in "${SCHEMAS[@]}"; do
        # Trim whitespace
        schema=$(echo "$schema" | xargs)
        PG_DUMP_CMD="$PG_DUMP_CMD --exclude-schema='$schema'"
    done
fi

# Add exclude-table-data options (keeps table structure but excludes data)
if [ -n "$EXCLUDE_TABLE_DATA" ]; then
    IFS=',' read -ra TABLES_DATA <<< "$EXCLUDE_TABLE_DATA"
    for table in "${TABLES_DATA[@]}"; do
        # Trim whitespace
        table=$(echo "$table" | xargs)
        PG_DUMP_CMD="$PG_DUMP_CMD --exclude-table-data='$table'"
    done
fi

if [ "$LOCAL_CLONE" = true ]; then
    echo -e "${YELLOW}Step 1/3: Creating database dump locally...${NC}"
    # Set password via environment variable (more secure than command line)
    export PGPASSWORD="$SOURCE_DB_PASSWORD"
    eval "$PG_DUMP_CMD"
    DUMP_RESULT=$?
    unset PGPASSWORD
else
    echo -e "${YELLOW}Step 1/5: Creating database dump on remote server...${NC}"
    # Execute pg_dump on remote server (PGPASSWORD is already in PG_DUMP_CMD)
    ssh -p ${REMOTE_PORT} ${REMOTE_USER}@${REMOTE_HOST} "$PG_DUMP_CMD"
    DUMP_RESULT=$?
fi

if [ $DUMP_RESULT -eq 0 ]; then
    echo -e "${GREEN}✓ Database dump created successfully${NC}"
else
    echo -e "${RED}✗ Failed to create database dump (exit code: $DUMP_RESULT)${NC}"
    exit 1
fi

if [ "$LOCAL_CLONE" = false ]; then
    echo ""
    echo -e "${YELLOW}Step 2/5: Checking dump file size...${NC}"
    REMOTE_SIZE=$(ssh -p ${REMOTE_PORT} ${REMOTE_USER}@${REMOTE_HOST} "ls -lh $REMOTE_DUMP_PATH | awk '{print \$5}'")
    REMOTE_SIZE_BYTES=$(ssh -p ${REMOTE_PORT} ${REMOTE_USER}@${REMOTE_HOST} "stat -f%z $REMOTE_DUMP_PATH 2>/dev/null || stat -c%s $REMOTE_DUMP_PATH 2>/dev/null")

    # Check if dump file is empty or too small (less than 1KB is suspicious)
    if [ -z "$REMOTE_SIZE_BYTES" ] || [ "$REMOTE_SIZE_BYTES" -lt 1024 ]; then
        echo -e "${RED}✗ Dump file is empty or too small (${REMOTE_SIZE_BYTES} bytes)${NC}"
        echo -e "${RED}This usually indicates a failed pg_dump. Check the error messages above.${NC}"
        exit 1
    fi

    echo -e "${GREEN}✓ Dump file size: ${REMOTE_SIZE}${NC}"

    # Compress on remote server if enabled
    if [ "$COMPRESSION_ENABLED" = true ]; then
        echo ""
        echo -e "${YELLOW}Step 3/5: Compressing dump file on remote server...${NC}"
        echo "Compression type: ${COMPRESSION_TYPE} (level: ${COMPRESSION_LEVEL})"

        ssh -p ${REMOTE_PORT} ${REMOTE_USER}@${REMOTE_HOST} "$COMPRESS_CMD $REMOTE_DUMP_PATH"

        if [ $? -eq 0 ]; then
            # Update paths to include compression extension
            REMOTE_DUMP_PATH="${REMOTE_DUMP_PATH}${COMPRESSION_EXT}"
            LOCAL_DUMP_PATH="${LOCAL_DUMP_PATH}${COMPRESSION_EXT}"

            COMPRESSED_SIZE=$(ssh -p ${REMOTE_PORT} ${REMOTE_USER}@${REMOTE_HOST} "ls -lh $REMOTE_DUMP_PATH | awk '{print \$5}'")
            COMPRESSED_SIZE_BYTES=$(ssh -p ${REMOTE_PORT} ${REMOTE_USER}@${REMOTE_HOST} "stat -f%z $REMOTE_DUMP_PATH 2>/dev/null || stat -c%s $REMOTE_DUMP_PATH 2>/dev/null")

            # Calculate compression ratio
            if [ -n "$REMOTE_SIZE_BYTES" ] && [ -n "$COMPRESSED_SIZE_BYTES" ]; then
                COMPRESSION_RATIO=$(awk "BEGIN {printf \"%.1f\", ($REMOTE_SIZE_BYTES / $COMPRESSED_SIZE_BYTES)}")
                SPACE_SAVED=$(awk "BEGIN {printf \"%.1f\", (($REMOTE_SIZE_BYTES - $COMPRESSED_SIZE_BYTES) / $REMOTE_SIZE_BYTES * 100)}")
                echo -e "${GREEN}✓ Compressed size: ${COMPRESSED_SIZE} (ratio: ${COMPRESSION_RATIO}x, saved: ${SPACE_SAVED}%)${NC}"
            else
                echo -e "${GREEN}✓ Compressed size: ${COMPRESSED_SIZE}${NC}"
            fi
        else
            echo -e "${RED}✗ Failed to compress dump file${NC}"
            exit 1
        fi
    else
        echo ""
        echo -e "${YELLOW}Step 3/5: Skipping compression (disabled)${NC}"
    fi

    echo ""
    echo -e "${YELLOW}Step 4/5: Transferring dump file to local server...${NC}"
    scp -P ${REMOTE_PORT} ${REMOTE_USER}@${REMOTE_HOST}:${REMOTE_DUMP_PATH} ${LOCAL_DUMP_PATH}

    if [ $? -eq 0 ]; then
        echo -e "${GREEN}✓ File transferred successfully${NC}"
        echo "Local path: ${LOCAL_DUMP_PATH}"
    else
        echo -e "${RED}✗ Failed to transfer file${NC}"
        exit 1
    fi

    echo ""
    echo -e "${YELLOW}Step 5/5: Cleaning up remote dump file...${NC}"
    ssh -p ${REMOTE_PORT} ${REMOTE_USER}@${REMOTE_HOST} "rm -f $REMOTE_DUMP_PATH"

    if [ $? -eq 0 ]; then
        echo -e "${GREEN}✓ Remote cleanup completed${NC}"
    else
        echo -e "${YELLOW}⚠ Warning: Failed to clean up remote dump file${NC}"
    fi

    # Decompress locally if compression was used
    if [ "$COMPRESSION_ENABLED" = true ]; then
        echo ""
        echo -e "${YELLOW}Decompressing file locally...${NC}"

        $DECOMPRESS_CMD "$LOCAL_DUMP_PATH"

        if [ $? -eq 0 ]; then
            # Remove compression extension from path
            LOCAL_DUMP_PATH="${LOCAL_DUMP_PATH%${COMPRESSION_EXT}}"
            LOCAL_SIZE=$(ls -lh "$LOCAL_DUMP_PATH" | awk '{print $5}')
            echo -e "${GREEN}✓ Decompressed successfully${NC}"
            echo "Decompressed size: ${LOCAL_SIZE}"
        else
            echo -e "${RED}✗ Failed to decompress file${NC}"
            exit 1
        fi
    fi
else
    # Local clone mode - dump already created locally
    echo ""
    echo -e "${YELLOW}Step 2/3: Checking dump file size...${NC}"
    LOCAL_SIZE=$(ls -lh "$LOCAL_DUMP_PATH" | awk '{print $5}')
    echo -e "${GREEN}✓ Dump file size: ${LOCAL_SIZE}${NC}"
fi

echo ""
if [ "$LOCAL_CLONE" = true ]; then
    echo -e "${GREEN}=== PostgreSQL Local Dump Created Successfully ===${NC}"
else
    echo -e "${GREEN}=== PostgreSQL Database Sync Completed Successfully ===${NC}"
fi
FINAL_DUMP_SIZE=$(ls -lh "$LOCAL_DUMP_PATH" | awk '{print $5}')
echo "Dump file: ${LOCAL_DUMP_PATH}"
echo "DUMP_SIZE=${FINAL_DUMP_SIZE}"

# Cleanup old dumps using retention policy
if [ "$RETENTION_ENABLED" = true ]; then
    # Use advanced GFS retention policy
    if command -v manage_retention &> /dev/null; then
        manage_retention "$DATABASE" "$LOCAL_DUMP_DIR"
    fi
elif [ "$KEEP_DUMPS" -ge 0 ]; then
    # Use simple retention (backward compatibility)
    echo ""

    if [ "$KEEP_DUMPS" -eq 0 ]; then
        echo -e "${YELLOW}Cleaning up all dumps (KEEP_DUMPS=0)...${NC}"
        # Delete all dumps for this database
        OLD_DUMPS=$(find "$LOCAL_DUMP_DIR" -name "${DATABASE}_*.dump" -type f 2>/dev/null)
        TOTAL_DUMPS=$(echo "$OLD_DUMPS" | grep -c "^" 2>/dev/null || echo 0)

        if [ "$TOTAL_DUMPS" -gt 0 ]; then
            echo "Deleting all $TOTAL_DUMPS dump(s)..."
            echo "$OLD_DUMPS" | while read -r dump_file; do
                if [ -f "$dump_file" ]; then
                    echo "  Deleting: $(basename "$dump_file")"
                    rm -f "$dump_file"
                fi
            done
            echo -e "${GREEN}✓ Cleanup completed${NC}"
        else
            echo -e "${GREEN}✓ No dumps found to clean${NC}"
        fi
    else
        echo -e "${YELLOW}Cleaning up old dumps (keeping last $KEEP_DUMPS)...${NC}"

        # Find all dump files for this database, sorted by modification time (oldest first)
        # Pattern: ${DATABASE}_*.dump
        OLD_DUMPS=$(find "$LOCAL_DUMP_DIR" -name "${DATABASE}_*.dump" -type f -printf '%T+ %p\n' 2>/dev/null | sort | awk '{print $2}')

        # Count total dumps
        TOTAL_DUMPS=$(echo "$OLD_DUMPS" | grep -c "^" 2>/dev/null || echo 0)

        if [ "$TOTAL_DUMPS" -gt "$KEEP_DUMPS" ]; then
            # Calculate how many to delete
            DELETE_COUNT=$((TOTAL_DUMPS - KEEP_DUMPS))

            echo "Found $TOTAL_DUMPS dumps, deleting oldest $DELETE_COUNT..."

            # Delete oldest dumps
            echo "$OLD_DUMPS" | head -n "$DELETE_COUNT" | while read -r dump_file; do
                if [ -f "$dump_file" ]; then
                    echo "  Deleting: $(basename "$dump_file")"
                    rm -f "$dump_file"
                fi
            done

            echo -e "${GREEN}✓ Cleanup completed${NC}"
        else
            echo -e "${GREEN}✓ No cleanup needed (found $TOTAL_DUMPS dumps, keeping $KEEP_DUMPS)${NC}"
        fi
    fi
fi

# Clear this command from bash history (security)
if [ -n "$BASH_VERSION" ]; then
    history -d $(history 1 | awk '{print $1}') 2>/dev/null || true
fi

# Auto restore if requested
if [ "$AUTO_RESTORE" = true ]; then
    echo ""
    if [ "$LOCAL_CLONE" = true ]; then
        echo -e "${GREEN}=== Starting PostgreSQL Database Clone (Step 3/3) ===${NC}"
    else
        echo -e "${GREEN}=== Starting PostgreSQL Database Restore ===${NC}"
    fi

    # Check if database exists
    echo -e "${YELLOW}Step 1/3: Checking if database exists...${NC}"

    # Set password via environment variable for all destination operations
    export PGPASSWORD="$DEST_DB_PASSWORD"

    DB_EXISTS=$(psql -U "$DEST_DB_USER" -h "$DEST_DB_HOST" -p "$DEST_DB_PORT" -t -c "SELECT 1 FROM pg_database WHERE datname='$DEST_DB_NAME'" postgres 2>/dev/null | xargs)

    if [ "$DB_EXISTS" = "1" ]; then
        echo -e "${YELLOW}Database '$DEST_DB_NAME' exists. Terminating active connections...${NC}"

        # Terminate all connections to the database
        psql -U "$DEST_DB_USER" -h "$DEST_DB_HOST" -p "$DEST_DB_PORT" -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname='$DEST_DB_NAME' AND pid <> pg_backend_pid();" postgres > /dev/null 2>&1

        echo -e "${YELLOW}Dropping database '$DEST_DB_NAME'...${NC}"
        dropdb -U "$DEST_DB_USER" -h "$DEST_DB_HOST" -p "$DEST_DB_PORT" "$DEST_DB_NAME" 2>&1

        if [ $? -eq 0 ]; then
            echo -e "${GREEN}✓ Database dropped successfully${NC}"
        else
            echo -e "${RED}✗ Failed to drop database${NC}"
            unset PGPASSWORD
            exit 1
        fi
    else
        echo -e "${GREEN}✓ Database does not exist, will create new one${NC}"
    fi

    echo ""
    echo -e "${YELLOW}Step 2/3: Creating database '$DEST_DB_NAME'...${NC}"
    createdb -U "$DEST_DB_USER" -h "$DEST_DB_HOST" -p "$DEST_DB_PORT" "$DEST_DB_NAME" 2>&1

    if [ $? -eq 0 ]; then
        echo -e "${GREEN}✓ Database created successfully${NC}"
    else
        echo -e "${RED}✗ Failed to create database${NC}"
        unset PGPASSWORD
        exit 1
    fi

    echo ""
    echo -e "${YELLOW}Step 3/3: Restoring backup to database...${NC}"
    echo "This may take a while depending on the database size..."
    echo ""

    pg_restore \
        --verbose \
        --no-owner \
        --no-privileges \
        --clean \
        --if-exists \
        --exit-on-error \
        -U "$DEST_DB_USER" \
        -h "$DEST_DB_HOST" \
        -p "$DEST_DB_PORT" \
        -d "$DEST_DB_NAME" \
        "$LOCAL_DUMP_PATH" 2>&1

    RESTORE_EXIT_CODE=${PIPESTATUS[0]}

    # Clear password from environment
    unset PGPASSWORD

    if [ $RESTORE_EXIT_CODE -eq 0 ]; then
        echo ""
        echo -e "${GREEN}✓ Database restored successfully${NC}"
    else
        echo ""
        echo -e "${YELLOW}⚠ Restore completed with some warnings (this is usually normal)${NC}"
    fi

    echo ""
    if [ "$LOCAL_CLONE" = true ]; then
        echo -e "${GREEN}=== PostgreSQL Database Clone Completed ===${NC}"
        echo "Cloned from: $DATABASE → $DEST_DB_NAME"
    else
        echo -e "${GREEN}=== PostgreSQL Database Restore Completed ===${NC}"
    fi

    # Run post-sync health checks on destination
    if [ "$HEALTH_CHECK_ENABLED" = true ] && [ "$HEALTH_CHECK_POST_SYNC" = true ]; then
        if command -v run_health_checks &> /dev/null; then
            run_health_checks "$DEST_DB_HOST" "$DEST_DB_PORT" "$DEST_DB_USER" "$DEST_DB_PASSWORD" "$DEST_DB_NAME" "Destination"

            if [ $? -ne 0 ] && [ "$HEALTH_CHECK_FAIL_ON_ERROR" = true ]; then
                echo -e "${YELLOW}⚠ Post-sync health check detected issues. Please review.${NC}"
            fi
        fi
    fi
else
    echo ""
    echo "To restore this dump manually, use:"
    echo "  export PGPASSWORD='yourpassword'"
    echo "  pg_restore --verbose --no-owner --no-privileges --clean --if-exists -U $DEST_DB_USER -h $DEST_DB_HOST -p $DEST_DB_PORT -d $DEST_DB_NAME \"$LOCAL_DUMP_PATH\""
    echo "  unset PGPASSWORD"
fi
